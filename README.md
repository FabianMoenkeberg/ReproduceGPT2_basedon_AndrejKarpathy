# ReproduceGPT2_basedon_AndrejKarpathy
Goal is to obtain detailed understanding of the GPT-model by reproducing the GPT-2 model following the video of  [Andrej Karpathy](https://www.youtube.com/watch?v=l8pRSuU81PU).

I know alread a lot about the theory of transformer models, including some [finetuning of Segformer](https://github.com/FabianMoenkeberg/SegFormer) using LoRA. However, a lot of practical details are still unclear to me. Especially, when it comes to training  a network like this.
By following the guide of Andrej Karpathy I hope to fill those gaps and abtain a clear picture about the complete process.

A friend and former colleague from EPFL, Luca Pegolotti, inspired me with his [article](https://medium.com/@pegolotti.luca/lets-reproduce-gpt-2-again-368711e0d1c5).

# Code Reference
The code from Andrej can be found [here](https://github.com/karpathy/build-nanogpt).

The code base of Luca can be found [here](https://github.com/lucapegolotti/gpt-2).